{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80909b56",
   "metadata": {},
   "source": [
    "# Cell 1 - Markdown\n",
    "\"\"\"\n",
    "# ModÃ¨le de Propension Ã  l'Achat\n",
    "## AnyCompany Food & Beverage - Phase 3 ML\n",
    "\n",
    "**Objectif** : PrÃ©dire la probabilitÃ© qu'un client effectue un achat dans les 30 prochains jours\n",
    "\n",
    "**Approche** : Classification binaire avec :\n",
    "- RÃ©gression Logistique\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import snowflake.connector\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ… BibliothÃ¨ques importÃ©es\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebaed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Connexion et extraction\n",
    "# Connexion Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user = \"THANDIE\",\n",
    "    password = \"MyCodexCodeESGstu357$\",\n",
    "    account = \"MWYCFSC-YKB13542\",\n",
    "    warehouse = \"ANYCOMPANY_WH\",\n",
    "    database = \"ANYCOMPANY_LAB\",\n",
    "    schema = \"SILVER\"\n",
    ")\n",
    "\n",
    "# Extraction des donnÃ©es\n",
    "query = \"\"\"\n",
    "WITH customer_features AS (\n",
    "    SELECT \n",
    "        cd.customer_id,\n",
    "        cd.age,\n",
    "        cd.annual_income,\n",
    "        cd.gender,\n",
    "        cd.region,\n",
    "        -- Features comportementales\n",
    "        COUNT(DISTINCT ft.transaction_id) AS total_purchases,\n",
    "        SUM(ft.amount) AS lifetime_value,\n",
    "        ROUND(AVG(ft.amount), 2) AS avg_order_value,\n",
    "        DATEDIFF(day, MAX(ft.transaction_date), CURRENT_DATE()) AS days_since_last_purchase,\n",
    "        -- Engagement promotions\n",
    "        COUNT(DISTINCT CASE WHEN p.promotion_id IS NOT NULL THEN ft.transaction_id END) AS promo_purchases,\n",
    "        -- Target : achat dans les 30 derniers jours\n",
    "        CASE \n",
    "            WHEN MAX(ft.transaction_date) >= DATEADD(day, -30, CURRENT_DATE()) THEN 1 \n",
    "            ELSE 0 \n",
    "        END AS purchased_recently\n",
    "    FROM SILVER.customer_demographics_clean cd\n",
    "    LEFT JOIN SILVER.financial_transactions_clean ft ON cd.customer_id = ft.customer_id\n",
    "    LEFT JOIN SILVER.promotions_clean p \n",
    "        ON ft.region = p.region \n",
    "        AND ft.transaction_date BETWEEN p.start_date AND p.end_date\n",
    "    WHERE ft.transaction_type = 'Sale'\n",
    "    GROUP BY cd.customer_id, cd.age, cd.annual_income, cd.gender, cd.region\n",
    "    HAVING COUNT(DISTINCT ft.transaction_id) >= 2\n",
    ")\n",
    "SELECT * FROM customer_features\n",
    "LIMIT 10000\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"ðŸ“Š {len(df)} clients extraits\")\n",
    "print(f\"Target distribution : {df['PURCHASED_RECENTLY'].value_counts().to_dict()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 - PrÃ©paration des donnÃ©es\n",
    "# PrÃ©paration des features\n",
    "# Encoder les variables catÃ©gorielles\n",
    "df_encoded = pd.get_dummies(df, columns=['GENDER', 'REGION'], drop_first=True)\n",
    "\n",
    "# Features et target\n",
    "feature_cols = [col for col in df_encoded.columns if col not in ['CUSTOMER_ID', 'PURCHASED_RECENTLY']]\n",
    "X = df_encoded[feature_cols]\n",
    "y = df_encoded['PURCHASED_RECENTLY']\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"âœ… DonnÃ©es prÃ©parÃ©es\")\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Test: {X_test.shape}\")\n",
    "print(f\"  Features: {len(feature_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79657abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 - ModÃ¨le 1 : RÃ©gression Logistique\n",
    "# RÃ©gression Logistique\n",
    "print(\"ðŸ”„ EntraÃ®nement RÃ©gression Logistique...\")\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# PrÃ©dictions\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Ã‰valuation\n",
    "print(\"\\nðŸ“Š RÃ‰GRESSION LOGISTIQUE - RÃ©sultats\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_lr):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beba73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - ModÃ¨le 2 : Random Forest\n",
    "# Random Forest\n",
    "print(\"ðŸ”„ EntraÃ®nement Random Forest...\")\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# PrÃ©dictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Ã‰valuation\n",
    "print(\"\\nðŸ“Š RANDOM FOREST - RÃ©sultats\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_rf):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f07e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 - Comparaison des modÃ¨les\n",
    "# Comparaison ROC Curves\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_score(y_test, y_pred_proba_lr):.4f})', linewidth=2)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_score(y_test, y_pred_proba_rf):.4f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='AlÃ©atoire')\n",
    "plt.xlabel('Taux de Faux Positifs')\n",
    "plt.ylabel('Taux de Vrais Positifs')\n",
    "plt.title('Courbes ROC - Comparaison des ModÃ¨les')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 - Feature Importance\n",
    "# Feature Importance (Random Forest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_importance.head(10)['Feature'], feature_importance.head(10)['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 10 Features les Plus Importantes')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Top 10 Features :\")\n",
    "print(feature_importance.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 - Matrice de confusion\n",
    "# Matrice de confusion\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Logistic Regression\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "ax1.set_title('Matrice de Confusion - RÃ©gression Logistique')\n",
    "ax1.set_ylabel('Vraie Classe')\n",
    "ax1.set_xlabel('Classe PrÃ©dite')\n",
    "\n",
    "# Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=ax2)\n",
    "ax2.set_title('Matrice de Confusion - Random Forest')\n",
    "ax2.set_ylabel('Vraie Classe')\n",
    "ax2.set_xlabel('Classe PrÃ©dite')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff83487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 - Recommandations\n",
    "\"\"\"\n",
    "## ðŸ’¼ RECOMMANDATIONS BUSINESS\n",
    "\n",
    "### Utilisation du ModÃ¨le\n",
    "\n",
    "Le modÃ¨le de propension Ã  l'achat peut Ãªtre utilisÃ© pour :\n",
    "\n",
    "1. **ðŸŽ¯ Ciblage Marketing PrÃ©dictif**\n",
    "   - Identifier les clients Ã  forte probabilitÃ© d'achat\n",
    "   - Personnaliser les campagnes par scoring\n",
    "\n",
    "2. **ðŸ“§ Automation Email**\n",
    "   - DÃ©clencher emails automatiques pour clients >70% probabilitÃ©\n",
    "   - Offres spÃ©ciales pour clients 40-70%\n",
    "\n",
    "3. **ðŸ’° Optimisation Budget**\n",
    "   - Concentrer budget sur clients Ã  fort potentiel\n",
    "   - RÃ©duire coÃ»ts d'acquisition\n",
    "\n",
    "### Prochaines Ã‰tapes\n",
    "\n",
    "âœ… DÃ©ployer le modÃ¨le en production  \n",
    "âœ… Automatiser le scoring mensuel  \n",
    "âœ… Tests A/B pour mesurer l'impact  \n",
    "âœ… Enrichir avec donnÃ©es comportementales additionnelles\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
